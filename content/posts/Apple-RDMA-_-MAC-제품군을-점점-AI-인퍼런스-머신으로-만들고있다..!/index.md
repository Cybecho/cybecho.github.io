---
title: "Apple RDMA : MAC 제품군을 점점 AI 인퍼런스 머신으로 만들고있다..!"
date: 2025-12-21T02:34:00.000Z
draft: false
tags: ["Infra"]
series: ["Infra & Network"]
description: "Apple은 macOS 15.2에서 Thunderbolt 5를 통해 RDMA(Remote Direct Memory Access)를 지원하기 시작하며, 이를 통해 소비자용 Mac에서 AI 인퍼런스 머신으로의 전환을 시도하고 있다. RDMA는 CPU 개입 없이 메모리 간 직접 데이터를 전송하여 성능을 극대화하고, Thunderbolt 5의 특성을 활용해 물리적으로 가까운 고성능 컴퓨팅 노드들을 연결하는 새로운 형태의 컴퓨팅 구성을 제안한다. 이를 통해 Apple은 클라우드와 온디바이스 AI의 중간 지점인 \"Edge AI Cluster\"를 형성하고, 데이터 프라이버시와 성능을 동시에 충족할 수 있는 가능성을 열어준다. 또한, 소프트웨어 생태계의 발전과 NVIDIA 의존도 탈피를 통해 AI 컴퓨팅 시장의 다변화를 추구하고 있다."
notion_id: "2d01bab9-e3f8-802a-b3d1-edc4cab6dc5d"
notion_url: "https://www.notion.so/Apple-RDMA-MAC-AI-2d01bab9e3f8802ab3d1edc4cab6dc5d"
---

# Apple RDMA : MAC 제품군을 점점 AI 인퍼런스 머신으로 만들고있다..!

> **Summary**
> Apple은 macOS 15.2에서 Thunderbolt 5를 통해 RDMA(Remote Direct Memory Access)를 지원하기 시작하며, 이를 통해 소비자용 Mac에서 AI 인퍼런스 머신으로의 전환을 시도하고 있다. RDMA는 CPU 개입 없이 메모리 간 직접 데이터를 전송하여 성능을 극대화하고, Thunderbolt 5의 특성을 활용해 물리적으로 가까운 고성능 컴퓨팅 노드들을 연결하는 새로운 형태의 컴퓨팅 구성을 제안한다. 이를 통해 Apple은 클라우드와 온디바이스 AI의 중간 지점인 "Edge AI Cluster"를 형성하고, 데이터 프라이버시와 성능을 동시에 충족할 수 있는 가능성을 열어준다. 또한, 소프트웨어 생태계의 발전과 NVIDIA 의존도 탈피를 통해 AI 컴퓨팅 시장의 다변화를 추구하고 있다.

---

![Image](image_3c4737b06363.png)

## 초기 관찰: RDMA는 무엇이 특별한가?

🔗 [https://www.jeffgeerling.com/blog/2025/15-tb-vram-on-mac-studio-rdma-over-thunderbolt-5](https://www.jeffgeerling.com/blog/2025/15-tb-vram-on-mac-studio-rdma-over-thunderbolt-5)

🔗 [https://news.hada.io/topic?id=25195](https://news.hada.io/topic?id=25195)

Apple이 macOS 15.2에서 RDMA(Remote Direct Memory Access)를 Thunderbolt 5를 통해 지원하기 시작했다는 발표는 표면적으로는 단순한 기술적 개선처럼 보인다. 하지만 RDMA는 전통적으로 데이터센터와 HPC(High Performance Computing) 환경에서 사용되던 기술이다. 왜 Apple이, 그것도 소비자용 Mac에서 이 기술을 도입하는가? 이 질문의 답을 찾기 위해서는 RDMA의 본질부터 이해해야 한다.

공감했다는 구절 - "서드파티 소프트웨어가 미리 대응하도록 RDMA를 선공개"했다는 해석과 "4대의 Studio를 묶어 LLM 인퍼런싱 클러스터로 쓰기 위한 기능"이라는 분석 - 은 Apple의 전략적 의도를 꿰뚫어 보는 통찰이다. 이 가설을 중심으로 기술적, 전략적, 사회적 차원을 탐구해보자.

## 1단계: RDMA의 본질적 이해

### 전통적 네트워크 통신의 한계

일반적인 TCP/IP 네트워크에서 데이터를 전송할 때는 여러 단계를 거쳐야 한다. 애플리케이션이 데이터를 커널 공간으로 복사하고, 운영체제 커널이 네트워크 프로토콜 스택을 처리하며, 데이터를 네트워크 인터페이스 카드로 전송한다. 수신 측에서도 동일한 과정이 역순으로 반복된다. 이 과정에서 CPU는 지속적으로 개입해야 하고, 데이터는 여러 번 복사된다. 메모리 복사(memory copy)는 특히 대용량 데이터를 다룰 때 심각한 병목이 된다.

RDMA는 이 문제를 근본적으로 해결한다. CPU를 거치지 않고 한 컴퓨터의 메모리에서 다른 컴퓨터의 메모리로 직접 데이터를 전송한다. 이는 마치 두 컴퓨터가 하나의 거대한 공유 메모리 공간을 가진 것처럼 작동하게 만든다. 전통적인 방식과 비교하면 다음과 같다:

**전통적 네트워크 통신:**

1. 애플리케이션 → 커널 메모리 복사
1. 커널의 프로토콜 스택 처리 (CPU 집약적)
1. 네트워크 카드로 전송
1. 수신 측에서 역순 반복
**RDMA:**

1. 애플리케이션이 원격 메모리 주소 지정
1. 하드웨어가 직접 메모리 간 전송
1. CPU 개입 최소화
1. 제로카피(zero-copy) 달성
### 기존 RDMA 구현의 두 갈래

데이터센터에서 RDMA는 주로 두 가지 형태로 구현되어 왔다. InfiniBand는 처음부터 RDMA를 위해 설계된 전용 네트워크 아키텍처로, 매우 낮은 레이턴시(약 1μs)와 높은 대역폭(200Gbps+)을 제공하지만 전용 하드웨어와 스위치가 필요해 비용이 높다. NVIDIA의 Mellanox 인수는 AI 시대에 InfiniBand의 중요성을 보여준다. RoCE(RDMA over Converged Ethernet)는 기존 이더넷 인프라에서 RDMA를 구현하는 방식으로 비용은 낮지만 InfiniBand만큼의 성능을 내기는 어렵다.

그런데 Apple은 Thunderbolt 5를 선택했다. 이 선택이 의미하는 바를 이해하려면 Thunderbolt 5의 특성을 살펴봐야 한다.

## 2단계: Thunderbolt 5의 전략적 선택

### 기술적 특성과 물리적 제약

Thunderbolt 5는 2023년 발표된 최신 인터페이스로 양방향 80Gbps, Bandwidth Boost 모드에서는 한 방향 120Gbps의 대역폭을 제공한다. 이는 InfiniBand의 초기 버전들과 비교해도 결코 뒤지지 않는 수준이다. 하지만 더 중요한 것은 Thunderbolt의 물리적 특성이다. 케이블 길이는 최대 2m로 제한되며(능동 케이블 사용 시 더 길어질 수 있음), PCIe 터널링을 지원하고, DisplayPort와 USB, 전원 전송까지 통합한다. 데이지체인으로 최대 6개 디바이스를 연결할 수 있다.

여기서 흥미로운 점이 드러난다. Thunderbolt는 장거리 데이터센터 네트워킹이 아니라 물리적으로 가까운 고성능 컴퓨팅 노드들을 연결하기 위한 최적의 선택이다. 이는 전통적인 서버 클러스터가 아닌 새로운 형태의 컴퓨팅 구성을 암시한다.

### Mac Studio라는 독특한 포지셔닝

Jeff Geerling의 실험은 매우 시사적이다. 그는 4대의 Mac Studio를 Thunderbolt 5로 연결하여 총 15TB의 통합 메모리 풀을 구성했다. 각 Mac Studio는 M2 Ultra 기준 최대 192GB, M4 Max 기준 최대 128GB의 통합 메모리를 가질 수 있어, 4대를 연결하면 512GB에서 768GB의 통합 메모리 풀이 가능하다. 하지만 단순히 메모리 용량만의 문제가 아니다. Apple Silicon의 통합 메모리 아키텍처(Unified Memory Architecture)가 여기서 결정적인 차이를 만든다.

## 3단계: 통합 메모리의 패러다임

### 전통적 아키텍처의 근본적 한계

전통적인 컴퓨터 아키텍처에서 CPU와 GPU는 별도의 메모리를 사용한다. 데이터를 GPU에서 처리하려면 CPU 메모리에서 데이터를 읽고, PCIe 버스를 통해 GPU 메모리로 복사하며, GPU에서 처리한 후 결과를 다시 CPU 메모리로 복사해야 한다. 이 과정에서 발생하는 오버헤드는 특히 LLM 추론에서 치명적이다. LLM 추론은 거대한 모델 파라미터를 메모리에 상주시켜야 하고, 각 토큰 생성마다 전체 모델 가중치에 접근해야 하며, 메모리 대역폭이 성능의 직접적 병목이 되기 때문이다.

Apple의 통합 메모리는 CPU, GPU, Neural Engine이 동일한 물리적 메모리를 공유한다. 데이터 복사가 필요 없고, 메모리 대역폭을 최대한 활용할 수 있다. 이는 단순한 성능 개선이 아니라 아키텍처적 패러다임의 전환이다.

### RDMA와 통합 메모리의 시너지

4대의 Mac Studio를 Thunderbolt 5 RDMA로 연결하면 각 머신의 통합 메모리가 논리적으로 하나의 거대한 메모리 풀처럼 작동할 수 있다. 405B 파라미터 Llama 모델을 예로 들면, FP16 정밀도로 약 810GB, 4bit 양자화로 약 203GB의 메모리가 필요하다. 단일 Mac Studio로는 불가능하지만 4대를 연결하면 충분하다.

더 중요한 것은 모델을 분산시키는 방식이다. 전통적인 모델 병렬화에서는 네트워크를 통한 통신 오버헤드, 각 노드에서 CPU-GPU 메모리 복사 오버헤드, 복잡한 동기화가 필요하다. 하지만 RDMA와 통합 메모리를 결합하면 직접 메모리 접근으로 네트워크 오버헤드를 최소화하고, 통합 메모리로 CPU-GPU 복사가 불필요하며, 하드웨어 레벨 동기화가 가능해진다. 이는 단순히 여러 컴퓨터를 연결하는 것이 아니라, 하나의 거대한 통합 메모리 시스템을 구축하는 것에 가깝다.

## 4단계: 새로운 카테고리의 탄생 - "Edge AI Cluster"

### 전통적 이분법의 한계

현재 AI 컴퓨팅은 크게 두 가지로 나뉜다. 클라우드 AI는 무제한 확장성과 최신 하드웨어를 제공하지만 레이턴시, 프라이버시, 대규모 사용 시 비용 문제가 있다. 온디바이스 AI는 프라이버시, 낮은 레이턴시, 오프라인 작동이 가능하지만 제한된 모델 크기와 성능 한계가 명확하다.

Apple의 RDMA over Thunderbolt는 제3의 카테고리를 제안한다. 물리적으로 가까운 여러 디바이스를 고속으로 연결하여 클라우드급 성능을 로컬에서 실현하고, 프라이버시와 성능의 균형을 맞추는 "Edge AI Cluster"다. 이는 완전히 새로운 컴퓨팅 패러다임이다.

### 구체적 사용 사례의 탐색

영화 제작 스튜디오에서는 4대의 Mac Studio로 로컬 LLM 클러스터를 구성하여 시나리오 생성, 대화 개선, 번역 등을 완전히 사내에서 처리할 수 있고, 민감한 각본이 외부 클라우드로 나가지 않는다. 의료 연구소에서는 환자 데이터로 훈련된 맞춤형 의료 AI를 HIPAA 준수를 위해 건물 밖으로 데이터를 내보내지 않으면서도 충분한 컴퓨팅 파워를 확보할 수 있다. 금융 트레이딩에서는 초저지연 요구사항과 독점 알고리즘의 기밀성 때문에 클라우드 왕복 시간이 너무 길어 로컬 추론이 필수적이다. 개발자나 연구자는 개인 연구실이나 소규모 팀에서 Llama 3 405B 같은 대형 모델을 실험하면서 클라우드 API 비용 부담 없이 작업할 수 있다.

이런 사용 사례들은 모두 공통점이 있다. 클라우드만큼 강력하면서도 로컬의 통제권을 유지해야 하는 필요성이다. 이것이 바로 Edge AI Cluster가 채우는 시장의 빈 공간이다.

## 5단계: 더 깊은 의문들 - 소프트웨어 생태계

### "서드파티 소프트웨어가 미리 대응하도록"의 의미

공감했다는 구절 중 이 부분이 특히 흥미롭다. Apple이 하드웨어 기능을 미리 공개하는 것은 소프트웨어 생태계가 준비할 시간을 주기 위함이다. 현재 분산 LLM 추론을 위한 프레임워크들 - vLLM, Ray Serve, DeepSpeed, Hugging Face Accelerate - 은 대부분 CUDA나 ROCm을 가정한다. Metal 지원은 제한적이고, RDMA over Thunderbolt는 전혀 고려되지 않았다.

Apple이 RDMA를 발표함으로써 PyTorch와 TensorFlow의 Metal 백엔드 개선이 촉진되고, llama.cpp 같은 커뮤니티 프로젝트의 최적화가 이루어지며, MLX(Apple의 ML 프레임워크) 확장이 가능해진다. 특히 MLX는 주목할 만하다. Apple이 개발한 이 프레임워크는 통합 메모리 아키텍처에 최적화되어 있고, Lazy evaluation으로 메모리 효율성을 극대화하며, Swift와 Python 바인딩으로 접근성을 제공한다. MLX에 RDMA 지원이 추가되면 여러 Mac을 하나의 거대한 ML 가속기처럼 사용할 수 있다.

### 타이밍의 전략적 의미

macOS 15.2는 아직 베타다. 실제 하드웨어 제품도 제한적이다. 왜 이렇게 일찍 공개할까? 가능한 해석은 여러 가지다. 2025년 상반기에 Thunderbolt 5 탑재 Mac Studio 발표가 예정되어 있을 수 있고, WWDC 2025에서 AI 관련 주요 발표를 준비 중일 수 있으며, 개발자들이 6개월에서 1년의 준비 시간이 필요하기 때문일 수 있다.

Apple의 역사적 패턴을 보면 Metal API는 2014년에 발표되고 GPU 집약적 Mac들은 그 이후 나왔으며, ARM Mac은 2020년 WWDC에서 발표되고 실제 제품은 11월에 출시되었고, Apple Intelligence는 2024년 WWDC에서 발표되고 실제 기능은 점진적으로 출시되었다. 하드웨어 제품 출시 6-12개월 전에 소프트웨어 API를 공개하는 것은 Apple의 전형적인 패턴이다.

## 6단계: 경쟁 지형의 재편

### NVIDIA 의존도 탈피의 전략적 가치

현재 AI 컴퓨팅은 NVIDIA에 극도로 의존적이다. H100 GPU 공급 부족, 높은 가격, CUDA 생태계 락인 문제가 심각하다. Apple이 제안하는 대안은 소비자가 직접 구매 가능한 Mac Studio, Metal과 MLX 기반 오픈 소프트웨어 스택, 전력 효율성으로 구성된다.

전력 효율성은 특히 중요하면서도 과소평가되는 요소다. 데이터센터 운영에서 전력은 점점 더 큰 제약이 되고 있다. NVIDIA H100은 TDP 700W이고, Mac Studio M2 Ultra는 전체 시스템이 약 200W다. 4대 클러스터 기준으로 H100 4대는 2,800W에 냉각을 더하면 약 4,000W이고, Mac Studio 4대는 800W에 냉각을 더하면 약 1,200W다. 1년 운영 비용을 전기료 $0.12/kWh로 계산하면 H100 클러스터는 $4,200, Mac Studio 클러스터는 $1,260이다. 이는 환경적으로도 경제적으로도 의미 있는 차이다.

### 새로운 시장 포지셔닝

흥미롭게도 AMD와 Intel도 비슷한 방향을 모색하고 있다. AMD MI300X는 통합 메모리 아키텍처를 채택했고, Intel Ponte Vecchio는 타일 기반 아키텍처를 사용한다. 하지만 이들은 여전히 데이터센터 중심이다. Apple의 접근은 프로슈머 시장에 초점을 맞춘다는 점에서 차별화된다.

NVIDIA H100 한 대는 $30,000에서 $40,000이고, Mac Studio M2 Ultra 4대도 $32,000에서 $40,000으로 비슷하지만, 전력 소비는 Mac이 약 1/5 수준이다. 가격은 비슷하지만 접근성과 운영 비용에서 차이가 난다. 더 중요한 것은 Apple이 기존 시장을 정면 공격하지 않고 새로운 카테고리를 만드는 경향이 있다는 점이다. iPhone으로 모바일 컴퓨팅을 재정의했고, AirPods로 오디오 시장을 재편했으며, Apple Silicon으로 PC 아키텍처에 도전했다. RDMA over Thunderbolt도 같은 맥락에서 이해할 수 있다.

## 7단계: 최종 종합 - 의의와 한계

### 기술적 차원의 혁신

통합 메모리와 RDMA의 결합은 독특한 조합이다. 이것은 분산 컴퓨팅에 대한 새로운 접근을 제시한다. 전통적인 분산 시스템에서는 네트워크가 병목이고 메모리 복사가 오버헤드였지만, Apple의 접근은 이 두 가지를 동시에 해결한다. AI 컴퓨팅의 에너지 소비가 지속가능성 문제가 되는 시점에 Apple Silicon의 전력 효율성은 중요한 대안이다. Thunderbolt는 Intel과 Apple이 함께 개발한 개방형 표준이므로 다른 제조사들도 채택 가능하다는 점에서 표준화 가능성도 있다.

### 전략적 차원의 의미

NVIDIA 독점에 대한 실질적 대안을 제공함으로써 시장을 다변화한다. 경쟁은 혁신을 촉진한다. Edge AI Cluster라는 새로운 카테고리는 클라우드와 온디바이스 사이의 백지 공간을 채운다. Apple은 하드웨어를 제공하고 커뮤니티가 소프트웨어를 구축하도록 장려하는 생태계 전략을 구사한다.

### 사회적 차원의 함의

데이터를 로컬에 유지하면서도 강력한 AI를 활용할 수 있다는 점에서 프라이버시가 강화된다. $40,000는 완벽하지는 않지만 수백만 달러 데이터센터보다는 접근 가능하다. AI 컴퓨팅이 소수 클라우드 제공자에게만 집중되지 않도록 하는 다극화 효과도 있다.

### 한계와 도전 과제

가격은 여전히 개인에게 부담스럽다. 소프트웨어 생태계 구축에는 시간이 필요하다. Apple의 장기 전략이 불명확하다는 불확실성도 있다. Thunderbolt는 InfiniBand보다 짧은 거리만 지원한다는 기술적 제약도 존재한다.

### 열린 가능성들

"4대의 Studio를 묶어 LLM 인퍼런싱 클러스터로 쓰기 위한 기능"이라는 해석은 매우 설득력 있다. 기술적, 전략적, 사회적 차원에서 이를 뒷받침하는 증거들이 있다. 하지만 동시에 불확실성을 포용해야 한다. 기술의 미래는 예측 불가능하다. Apple의 RDMA는 게임 체인저가 될 수도 있고, 니치 기능으로 남을 수도 있으며, 완전히 예상 밖의 용도로 사용될 수도 있다.

중요한 것은 가능성이 열렸다는 것이다. AI 컴퓨팅에 새로운 경로가 생겼다. 개발자들, 연구자들, 기업들이 실험하고 혁신하고 예상치 못한 것을 발견할 기회가 생겼다. 명확한 답이 아니라 더 좋은 질문들을 가능하게 만드는 것, 그것이 기술 발전의 본질이다. Apple의 RDMA over Thunderbolt는 새로운 질문들을 던진다. AI는 어떻게 조직되어야 하는가? 컴퓨팅 파워는 누구의 것인가? 미래의 연구실은 어떤 모습일까? 창의적 작업은 어떻게 변화할까? 이 질문들에 답하는 것은 우리 모두의 몫이다. Apple은 도구를 제공했고, 이제 우리가 그것으로 무엇을 만들지 결정할 차례다.

🎥 [동영상 보기](https://www.youtube.com/watch?v=bSq54AMAH0I)

